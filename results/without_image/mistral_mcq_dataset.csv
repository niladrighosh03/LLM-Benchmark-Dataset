pdf_name,chunk_number,total_chunks,pages,question,option_A,option_B,option_C,option_D,correct_answer
notes/LLM_cs124_week7_2025.pdf,1,"1, 2, 3",How does a large language model generate text?,By being trained on specific text to generate,By assigning probabilities to sequences of words and sampling possible next words,By learning to predict the next word only,By using a rule-based approach,B) By assigning probabilities to sequences of words and sampling possible next words
notes/LLM_cs124_week7_2025.pdf,1,"1, 2, 3",Which of the following is NOT a way a large language model generates text?,By assigning probabilities to sequences of words and sampling possible next words,By learning to predict the next word,By using a rule-based approach,By being trained on a specific text to generate,D) By being trained on a specific text to generate
notes/LLM_cs124_week7_2025.pdf,1,"1, 2, 3",A large language model is trained to do which of the following?,Assign probabilities to sequences of words and generate text by sampling possible next words,Learn a lot of useful language knowledge,Predict the next word in a sequence,Generate text by using a rule-based approach,B) Learn a lot of useful language knowledge
notes/LLM_cs124_week7_2025.pdf,2,"3, 4, 5","Which type of language model is described as 'Nice to generate from, can't condition on future words'?",Decoder-only model,Encoder-only model,Encoder-decoder model,Transformer model,A) Decoder-only model
notes/LLM_cs124_week7_2025.pdf,2,"3, 4, 5",Which term is used to describe language models that can't condition on future words during generation?,Autoregressive models,Causal models,Left-to-right models,Generator models,A) Autoregressive models
notes/LLM_cs124_week7_2025.pdf,2,"3, 4, 5",Which type of language model gets bidirectional context and can condition on future words?,Decoder-only model,Encoder-only model,Encoder-decoder model,Transformer model,B) Encoder-only model
notes/LLM_cs124_week7_2025.pdf,2,"3, 4, 5",Which term is used to describe language models that have both encoder and decoder components?,Autoregressive models,Causal models,Encoder-decoder models,Transformer models,C) Encoder-decoder models
notes/LLM_cs124_week7_2025.pdf,2,"3, 4, 5",Which pretraining method is best suited for decoder-only models?,Masked language modeling,Next sentence prediction,Sequence-to-sequence prediction,Contrastive prediction,C) Sequence-to-sequence prediction
notes/LLM_cs124_week7_2025.pdf,3,"5, 6, 7",Which model type is used for generating text but cannot condition on future words?,Decoder-only model,Encoder-only model,Transformer model,Recurrent neural network,A) Decoder-only model
notes/LLM_cs124_week7_2025.pdf,3,"5, 6, 7",Which model type gets bidirectional context and can condition on future words?,Decoder-only model,Encoder-only model,Transformer model,Encoder-decoder model,B) Encoder-only model
notes/LLM_cs124_week7_2025.pdf,3,"5, 6, 7","Which model type is popular for mapping from one sequence to another, such as machine translation and speech recognition?",Decoder-only model,Encoder-only model,Transformer model,Encoder-decoder model,D) Encoder-decoder model
notes/LLM_cs124_week7_2025.pdf,3,"5, 6, 7",Which type of pretraining is used for encoder-only models?,Predicting words from surrounding words on both sides,Predicting words left to right,Predicting words right to left,Predicting words based on future context,A) Predicting words from surrounding words on both sides
notes/LLM_cs124_week7_2025.pdf,3,"5, 6, 7",Which model type is used in the BERT family?,Decoder-only model,Encoder-only model,Transformer model,Encoder-decoder model,B) Encoder-only model
notes/LLM_cs124_week7_2025.pdf,4,"7, 8, 9",Which model type is used for generating text left-to-right?,Decoder-only model,Encoder-only model,Transformer model,RNN model,A) Decoder-only model
notes/LLM_cs124_week7_2025.pdf,4,"7, 8, 9",Which type of language model can't condition on future words?,Decoder-only model,Encoder-only model,Transformer model,RNN model,B) Encoder-only model
notes/LLM_cs124_week7_2025.pdf,4,"7, 8, 9",Which model type gets bidirectional context and can condition on future?,Decoder-only model,Encoder-only model,Transformer model,RNN model,C) Transformer model
notes/LLM_cs124_week7_2025.pdf,4,"7, 8, 9",Which pretraining method is best for decoder-only models?,Masked language modeling,Next sentence prediction,Autoregressive language modeling,Bidirectional language modeling,C) Autoregressive language modeling
notes/LLM_cs124_week7_2025.pdf,4,"7, 8, 9",Which term is another name for causal LLMs and autoregressive LLMs?,Decoder-only models,Encoder-only models,Left-to-right models,Transformer models,A) Decoder-only models
notes/LLM_cs124_week7_2025.pdf,5,"9, 10, 11","Given the sentence 'I like Jackie Chan', which sentiment is more probable according to the language model?",Positive,Negative,Neutral,Question,A) Positive
notes/LLM_cs124_week7_2025.pdf,5,"9, 10, 11",Which task can be cast as word prediction in NLP?,Sentiment analysis,Question answering,Text summarization,Speech recognition,B) Question answering
notes/LLM_cs124_week7_2025.pdf,5,"9, 10, 11",Which token should be added to the context for generating the next token in left-to-right text completion?,the,and,a,tl;dr,A) the
notes/LLM_cs124_week7_2025.pdf,5,"9, 10, 11",Which type of language model is used for text summarization?,Decoder-only,Encoder-only,Encoder-decoder,Transformer-based,C) Encoder-decoder
notes/LLM_cs124_week7_2025.pdf,5,"9, 10, 11",Which word is most likely to follow 'The Origin of Species' in a language model?,Charles,Darwin,The,is,B) Darwin
notes/LLM_cs124_week7_2025.pdf,6,"11, 12, 13","Given the sentence 'I like Jackie Chan', which word is more probable to come next based on the sentiment analysis?",positive,negative,sentiment,Chan,A) positive
notes/LLM_cs124_week7_2025.pdf,6,"11, 12, 13",Which token should be added after 'Who wrote the book ‘‘The Origin of Species’' for question answering using a language model?,Charles,question,Darwin,answer,A) Charles
notes/LLM_cs124_week7_2025.pdf,6,"11, 12, 13",Which task can be cast as word prediction using a language model?,Text summarization,Sentiment analysis,Question answering,Text generation,A) Text summarization
notes/LLM_cs124_week7_2025.pdf,6,"11, 12, 13",Which token should be added after 'text' for text summarization using a language model?,tl;dr,summary,article,text,A) tl;dr
notes/LLM_cs124_week7_2025.pdf,6,"11, 12, 13",Which model architecture is used for modern language models?,RNN,CNN,Transformer,LSTM,C) Transformer
notes/LLM_cs124_week7_2025.pdf,8,"15, 16, 17",Who proposed the idea of replacing RNNs with self-attention in the Transformer architecture?,Ashish Vaswani,Noam Shazeer,Jakob Uszkoreit,Niki Parmar,A) Ashish Vaswani
notes/LLM_cs124_week7_2025.pdf,8,"15, 16, 17",Which year did the Transformer architecture first appear in a paper?,2015,2017,2018,2019,B) 2017
notes/LLM_cs124_week7_2025.pdf,8,"15, 16, 17",Which team members were responsible for designing and implementing the first Transformer models?,Ashish Vaswani and Illia Polosukhin,Noam Shazeer and Niki Parmar,Jakob Uszkoreit and Llion Jones,"Ashish Vaswani, Noam Shazeer, Niki Parmar, and Llion Jones","D) Ashish Vaswani, Noam Shazeer, Niki Parmar, and Llion Jones"
notes/LLM_cs124_week7_2025.pdf,8,"15, 16, 17",Which machine translation task did the Transformer model achieve a new single-model state-of-the-art BLEU score on?,WMT 2014 English-to-German,WMT 2014 English-to-French,WMT 2015 English-to-Italian,WMT 2016 English-to-Spanish,B) WMT 2014 English-to-French
notes/LLM_cs124_week7_2025.pdf,8,"15, 16, 17",Which year did attention mechanisms first appear in the context of natural language processing?,2003,2012,2015,2018,C) 2015
notes/LLM_cs124_week7_2025.pdf,9,"17, 18, 19",Which event marked the beginning of the use of GPUs in deep learning?,The discovery of Static Word Embeddings in 2013,The introduction of Multi-Task Learning in 2008,The emergence of GPUs in 2004,The development of Transformers in 2017,C) The emergence of GPUs in 2004
notes/LLM_cs124_week7_2025.pdf,9,"17, 18, 19","Which technology was re-discovered in 2013, around the same time as the rise of Transformers?",Multi-Task Learning,Attention,Static Word Embeddings,Contextual Word Embeddings,C) Static Word Embeddings
notes/LLM_cs124_week7_2025.pdf,9,"17, 18, 19",Which deep learning technique was introduced before the emergence of Transformers?,Neural Language Model,Stacked Transformer Blocks,Input Encoding,Language Modeling Head,A) Neural Language Model
notes/LLM_cs124_week7_2025.pdf,9,"17, 18, 19",Which technology was used extensively in deep learning from 2012 onwards?,Multi-Task Learning,Transformers,GPUs,Contextual Word Embeddings,C) GPUs
notes/LLM_cs124_week7_2025.pdf,9,"17, 18, 19",Which deep learning component processes the input tokens and generates logits?,Language Modeling Head,Input Encoding,Stacked Transformer Blocks,Attention,A) Language Modeling Head
notes/LLM_cs124_week7_2025.pdf,10,"19, 20, 21","Given the context of the lecture, which type of word embeddings are static?",Contextual embeddings,Static embeddings (word2vec),Transformer block embeddings,Input token embeddings,B) Static embeddings (word2vec)
notes/LLM_cs124_week7_2025.pdf,10,"19, 20, 21",Which of the following is a problem with static word embeddings according to the lecture?,They are too complex,They don't reflect the meaning of a word in context,They are not widely used,They are computationally expensive,B) They don't reflect the meaning of a word in context
notes/LLM_cs124_week7_2025.pdf,10,"19, 20, 21",Which method is used to compute contextual embeddings according to the lecture?,Static embedding lookup,One-hot encoding,Attention mechanism,Transformer block processing,C) Attention mechanism
notes/LLM_cs124_week7_2025.pdf,10,"19, 20, 21","Consider the sentence 'The chicken crossed the road because it was too tired'. In the context of the lecture, which word's meaning is represented by its static embedding?",chicken,road,because,it,D) it
notes/LLM_cs124_week7_2025.pdf,10,"19, 20, 21",Which of the following is a type of embedding mentioned in the lecture that reflects the meaning of a word in different contexts?,Input token embeddings,Transformer block embeddings,Static embeddings (word2vec),Contextual embeddings,D) Contextual embeddings
notes/LLM_cs124_week7_2025.pdf,11,"21, 22, 23","Given the sentence 'The chicken didn't cross the road because it was too tired', which word is most likely to 'attend to' the word 'it'?",tired,chicken,road,because,A) tired
notes/LLM_cs124_week7_2025.pdf,11,"21, 22, 23",Which of the following contextual embeddings is most likely to have a different meaning when used in a different context?,The word 'is' in the sentence 'The cat is on the mat'.,The word 'is' in the sentence 'The cat is a mammal'.,The word 'mat' in the sentence 'The cat is on the mat'.,The word 'mat' in the sentence 'The cat is a mammal'.,C) The word 'mat' in the sentence 'The cat is on the mat'.
notes/LLM_cs124_week7_2025.pdf,11,"21, 22, 23",Which of the following words is most likely to 'attend to' the word 'it' in the sentence 'The chicken didn't cross the road because it was too wide'?,chicken,road,wide,because,C) wide
notes/LLM_cs124_week7_2025.pdf,11,"21, 22, 23",Which of the following words is least likely to have a different meaning depending on the surrounding words?,is,cat,mat,the,D) the
notes/LLM_cs124_week7_2025.pdf,11,"21, 22, 23",Which of the following words is most likely to 'attend to' the word 'it' in the sentence 'The chicken didn't cross the road because it was too tired' if the sentence was changed to 'The chicken didn't cross the road because it was too hot'?,tired,chicken,road,hot,D) hot
notes/LLM_cs124_week7_2025.pdf,12,"23, 24, 25",Why did the chicken not cross the road according to the intuition of attention?,Because it was too tired and didn't attend to the road,Because it was too hungry and attended only to the food,Because it was too busy attending to other chickens,Because it was too focused on the grass on the other side,A) Because it was too tired and didn't attend to the road
notes/LLM_cs124_week7_2025.pdf,12,"23, 24, 25",Which mechanism helps compute the embedding for a token by selectively attending to and integrating information from surrounding tokens?,Self-attention distribution,Intuition of attention,Layer k+1,Formal attention definition,D) Formal attention definition
notes/LLM_cs124_week7_2025.pdf,12,"23, 24, 25",What is the formal definition of attention in the context of the lecture?,A method for doing a weighted sum of vectors,A mechanism for helping compute the embedding for a token by selectively attending to and integrating information from surrounding tokens,A layer in a neural network,A neural network architecture,B) A mechanism for helping compute the embedding for a token by selectively attending to and integrating information from surrounding tokens
notes/LLM_cs124_week7_2025.pdf,12,"23, 24, 25",Why does the chicken not attend to the road in the given example?,Because it is too focused on the food,Because it is too tired,Because it is too busy attending to other chickens,Because it is too focused on the grass on the other side,A) Because it is too focused on the food
notes/LLM_cs124_week7_2025.pdf,12,"23, 24, 25",Which layer in a neural network contains the self-attention distribution columns corresponding to input tokens?,Layer k,Layer k+1,Layer k-1,Layer 0,B) Layer k+1
notes/LLM_cs124_week7_2025.pdf,13,"25, 26, 27","Given the self-attention mechanism, which equation calculates the score between a current focus of attention and a preceding context element?","score(xi, xj) = xi·xj","aij = softmax(score(xi, xj))",ai = Xj·iaijxj,"score(xi, xj) = qi·kj","D) score(xi, xj) = qi·kj"
notes/LLM_cs124_week7_2025.pdf,13,"25, 26, 27","In the self-attention mechanism, what is the role of the 'key' vectors in the dot product calculation?",They represent the current focus of attention,They represent the preceding context elements,They represent the value vectors,They represent the query vectors in the dot product calculation,B) They represent the preceding context elements
notes/LLM_cs124_week7_2025.pdf,13,"25, 26, 27",Which equation calculates the output value for the current focus of attention in self-attention?,"aij = softmax(score(xi, xj))",ai = Xj·iaijxj,"score(xi, xj) = qi·kj",ai = Xj·iaijvj,D) ai = Xj·iaijvj
notes/LLM_cs124_week7_2025.pdf,13,"25, 26, 27","In the self-attention mechanism, what is the dimensionality of the key and query vectors?",The same as the input and output vectors,Half the size of the input and output vectors,Twice the size of the input and output vectors,"A separate, smaller size for each",A) The same as the input and output vectors
notes/LLM_cs124_week7_2025.pdf,13,"25, 26, 27",Which of the following is NOT a role of an input embedding in the transformer model?,As the current focus of attention when being compared to all of the other preceding inputs,In its role as a preceding input being compared to the current focus of attention,As a value used to compute the output for the current focus of attention,As a control signal to determine the attention weights,D) As a control signal to determine the attention weights
notes/LLM_cs124_week7_2025.pdf,14,"27, 28, 29","Given the self-attention model, which equation calculates the score between a current focus of attention and a preceding input?","score(xi, xj) = xi·xj","aij = softmax(score(xi, xj))",ai = Xj·iaijxj,qi = xiWQ; ki = xiWK; vi = xiWV,C) ai = Xj·iaijxj
notes/LLM_cs124_week7_2025.pdf,14,"27, 28, 29","In the self-attention model, which vectors have the same dimensionality?",query and key vectors,key and value vectors,input and output vectors,query and value vectors,B) key and value vectors
notes/LLM_cs124_week7_2025.pdf,14,"27, 28, 29",Which equation calculates the output value for the current focus of attention in the self-attention model?,"score(xi, xj) = qi·kj","aij = softmax(score(xi, xj))",ai = Xj·iaijvj,ai = Xj·iaijxj,C) ai = Xj·iaijvj
notes/LLM_cs124_week7_2025.pdf,14,"27, 28, 29",What is the role of the dot product in the self-attention model?,It calculates the similarity between vectors,It normalizes the scores to create a probability distribution,It projects each input vector into a representation of its role,It performs the weighted sum using the probability distribution,A) It calculates the similarity between vectors
notes/LLM_cs124_week7_2025.pdf,14,"27, 28, 29",Which vectors in the self-attention model have different dimensions?,query and key vectors,key and value vectors,input and output vectors,query and value vectors,A) query and key vectors
notes/LLM_cs124_week7_2025.pdf,15,"29, 30, 31","Given the self-attention mechanism, which role does the 'query' vector play in the comparison process?",It is the preceding input being compared to the current element.,It is the current element being compared to the preceding inputs.,It determines the similarity between the current and preceding inputs.,It is the value of a preceding element that gets weighted and summed.,B) It is the current element being compared to the preceding inputs.
notes/LLM_cs124_week7_2025.pdf,15,"29, 30, 31","In the self-attention mechanism, which columns in the distribution of Layer k+1 correspond to the input tokens?",Columns corresponding to the query vectors.,Columns corresponding to the key vectors.,Columns corresponding to the value vectors.,Columns corresponding to the input tokens.,D) Columns corresponding to the input tokens.
notes/LLM_cs124_week7_2025.pdf,15,"29, 30, 31","Considering the self-attention mechanism, if the 'query' vector is more similar to the 'key' vector, what can be inferred about the relationship between the corresponding input tokens?",They are likely to be unrelated.,They are likely to be similar.,They are likely to be dissimilar.,Their relationship cannot be determined from the given information.,B) They are likely to be similar.
notes/LLM_cs124_week7_2025.pdf,15,"29, 30, 31","In the self-attention mechanism, which vector is weighted and summed based on the similarity between the 'query' and 'key' vectors?",The 'query' vector.,The 'key' vector.,The 'value' vector.,The 'xi' vector.,C) The 'value' vector.
notes/LLM_cs124_week7_2025.pdf,15,"29, 30, 31","Given the self-attention mechanism, if the 'query' vector is identical to the 'key' vector for a specific input token pair, what can be inferred about the attention distribution for those tokens?",The attention distribution will be maximized.,The attention distribution will be minimized.,The attention distribution will be neutral.,The attention distribution cannot be determined from the given information.,A) The attention distribution will be maximized.
notes/LLM_cs124_week7_2025.pdf,16,"31, 32, 33","Given the attention head in transformers, which role does the query vector play during the attention process?",It represents the current element being compared to the preceding inputs.,It represents the preceding input being compared to the current element.,It is the weighted sum of the prior element's key and value.,It is the projection of each input vector into a representation of its role as a value.,A) It represents the current element being compared to the preceding inputs.
notes/LLM_cs124_week7_2025.pdf,16,"31, 32, 33",Which equation is used to compute the dot product between the query vector and the key vector in the attention process?,Eq.9.10,Eq.9.11,Eq.9.12,Eq.9.13,B) Eq.9.11
notes/LLM_cs124_week7_2025.pdf,16,"31, 32, 33",What is the purpose of scaling the dot product in the attention process by a factor related to the size of the embeddings?,To avoid numerical issues and loss of gradients during training.,To increase the similarity between the query and key vectors.,To decrease the dimensionality of the query and key vectors.,To normalize the dot product into a probability distribution.,A) To avoid numerical issues and loss of gradients during training.
notes/LLM_cs124_week7_2025.pdf,16,"31, 32, 33",Which equation is used to compute the output for the current element ai in the attention process?,Eq.9.9,Eq.9.10,Eq.9.11,Eq.9.13,D) Eq.9.13
notes/LLM_cs124_week7_2025.pdf,16,"31, 32, 33",Which matrix is used to project each input vector into a representation of its role as a query in the attention process?,WK,WQ,WV,WX,B) WQ
notes/LLM_cs124_week7_2025.pdf,17,"33, 34, 35","Given the attention head in transformers, which role does the weight matrix WQ play?",It represents the current element being compared to preceding inputs.,It represents the preceding input being compared to the current element.,It projects each input vector into a representation of its role as a value.,It projects each input vector into a representation of its role as a query.,D) It projects each input vector into a representation of its role as a query.
notes/LLM_cs124_week7_2025.pdf,17,"33, 34, 35","In the attention process, which matrix is used to compute the similarity between the current and preceding elements?",WK,WQ,WV,The result of the dot product between qi and kj is used.,D) The result of the dot product between qi and kj is used.
notes/LLM_cs124_week7_2025.pdf,17,"33, 34, 35",Which equation in the attention process involves the softmax function?,Eq.9.11,Eq.9.12,Eq.9.13,Eq.9.14,A) Eq.9.11
notes/LLM_cs124_week7_2025.pdf,17,"33, 34, 35",Which matrix is used to project each input vector into a representation of its role as a value?,WQ,WK,WV,WX,C) WV
notes/LLM_cs124_week7_2025.pdf,17,"33, 34, 35","In the attention process, which step involves summing the weighted values of the prior elements?",Computing the dot product between qi and kj,Normalizing the scores into a probability distribution,Summing the weighted values of the prior elements,Computing the output for the current element,C) Summing the weighted values of the prior elements
notes/LLM_cs124_week7_2025.pdf,18,"35, 36, 37","Given the attention head equations, which matrix is multiplied with the input vector xi to obtain the query vector qi?",WK,WQ,WV,WO,B) WQ
notes/LLM_cs124_week7_2025.pdf,18,"35, 36, 37",Which matrix is used to reshape the output of the attention head to the desired output shape [1⇥d]?,WK,WQ,WV,WO,D) WO
notes/LLM_cs124_week7_2025.pdf,18,"35, 36, 37",What is the role of the matrix WO in the attention head calculation?,"It is used to project each input vector into a representation of its role as a key, query, or value.",It is used to compare the query vector of the current element with the key vectors of all preceding elements.,It is used to compute the dot product between the query vector and the key vector to determine the similarity weight.,It is used to reshape the output of the attention head and obtain the final output of the same dimensionality as the input.,D) It is used to reshape the output of the attention head and obtain the final output of the same dimensionality as the input.
notes/LLM_cs124_week7_2025.pdf,18,"35, 36, 37",Which matrix is used to project each input vector into a representation of its role as a value?,WK,WQ,WV,WO,C) WV
notes/LLM_cs124_week7_2025.pdf,18,"35, 36, 37",What is the purpose of the dot product between the query vector and the key vector in the attention head calculation?,It is used to obtain the scalar score of similarity between the current element and a preceding element.,"It is used to project each input vector into a representation of its role as a key, query, or value.",It is used to compute the weighted sum of the value vectors to obtain the final output for the current element.,It is used to reshape the output of the attention head and obtain the final output of the same dimensionality as the input.,A) It is used to obtain the scalar score of similarity between the current element and a preceding element.
notes/LLM_cs124_week7_2025.pdf,19,"37, 38, 39",Which method enriches the representation of a token by incorporating contextual information?,Summary Attention,Transformers Attention,Word Embedding,Long Short-Term Memory,B) Transformers Attention
notes/LLM_cs124_week7_2025.pdf,19,"37, 38, 39",What is the main function of the Transformer Block in the context of enriched representation?,It applies a feed-forward neural network to the enriched representation,It passes the enriched representation up to the next layer,It initializes the enriched representation with random values,It calculates the attention scores for each token,D) It calculates the attention scores for each token
notes/LLM_cs124_week7_2025.pdf,19,"37, 38, 39",Which of the following is NOT a function of the Transformer Block?,It passes the enriched representation up to the next layer,It applies a feed-forward neural network to the enriched representation,It calculates the attention scores for each token and passes them to the next layer,It initializes the enriched representation with random values,C) It calculates the attention scores for each token and passes them to the next layer
notes/LLM_cs124_week7_2025.pdf,19,"37, 38, 39","Given two contexts, Context A and Context B, which of the following is true about the enriched representation of a word in Context A compared to its enriched representation in Context B?",They will be identical because context does not affect the enriched representation,They will be identical because the Transformer Block does not consider context,They will be different because the Transformer Block considers context,They will be different because the Transformer Block does not pass the enriched representation up to the next layer,C) They will be different because the Transformer Block considers context
notes/LLM_cs124_week7_2025.pdf,19,"37, 38, 39",Which of the following is a valid function of attention scores in the context of the Transformer Block?,They are used to initialize the enriched representation with random values,They are used to calculate the final output of the model,They are used to determine which tokens to focus on in the next layer,They are used to calculate the similarity between words in different contexts,D) They are used to calculate the similarity between words in different contexts
notes/LLM_cs124_week7_2025.pdf,20,"39, 40, 41","Given the Transformer architecture, which component modifies each token and passes it up the stack?",Layer Norm,MultiHeadAttention,Feedforward Network,Language Modeling Head,C) Feedforward Network
notes/LLM_cs124_week7_2025.pdf,20,"39, 40, 41",Which component in the Transformer architecture is responsible for self-attention between input tokens?,Layer Norm,MultiHeadAttention,Feedforward Network,Language Modeling Head,B) MultiHeadAttention
notes/LLM_cs124_week7_2025.pdf,20,"39, 40, 41",Which part of the Transformer architecture applies layer normalization to the input and output of each sub-layer?,Input Encoding,Language Modeling Head,Layer Norm,MultiHeadAttention,C) Layer Norm
notes/LLM_cs124_week7_2025.pdf,20,"39, 40, 41","Considering the Transformer architecture, which component is responsible for the feedforward network in each sub-layer?",Input Encoding,Language Modeling Head,Layer Norm,Feedforward Network,D) Feedforward Network
notes/LLM_cs124_week7_2025.pdf,20,"39, 40, 41","Given the Transformer architecture, which component computes the logits for the language modeling head?",Input Encoding,Language Modeling Head,Layer Norm,MultiHeadAttention,B) Language Modeling Head
notes/LLM_cs124_week7_2025.pdf,21,"41, 42, 43","Given a transformer block, which layer normalization occurs before the attention and feedforward layers?",After the attention and feedforward layers,Before the attention layer only,Before the feedforward layer only,Both before the attention and feedforward layers,D) Both before the attention and feedforward layers
notes/LLM_cs124_week7_2025.pdf,21,"41, 42, 43",What is the dimensionality of the hidden layer in the feedforward network of a transformer model?,The same as the model dimensionality,Larger than the model dimensionality but the same for each layer,Smaller than the model dimensionality and different for each layer,The same as the model dimensionality but different for each layer,B) Larger than the model dimensionality but the same for each layer
notes/LLM_cs124_week7_2025.pdf,21,"41, 42, 43",Which layer in a transformer block receives an embedding for a token as its input?,The attention layer,The feedforward layer,The layer norm after the attention layer,The layer norm before the attention layer,A) The attention layer
notes/LLM_cs124_week7_2025.pdf,21,"41, 42, 43",Which of the following is NOT a component of a transformer block's residual stream?,The initial embedding for a token,The output of the attention layer,The output of the feedforward layer,The sum of the outputs from the attention and feedforward layers,B) The output of the attention layer
notes/LLM_cs124_week7_2025.pdf,21,"41, 42, 43",What is the purpose of the layer norm computation in a transformer block?,To add the input of a component to its output,To normalize the vector twice,To perform multi-head attention,To apply a fully-connected 2-layer network,B) To normalize the vector twice
notes/LLM_cs124_week7_2025.pdf,22,"43, 44, 45","Given an embedding vector x of dimensionality d, which values are calculated in the first step of layer normalization?",Mean and standard deviation over all elements of x,Gain and offset values for normalization,Mean and standard deviation over all elements of xi-1 and xi+1,Gain and offset values for multi-head attention,A) Mean and standard deviation over all elements of x
notes/LLM_cs124_week7_2025.pdf,22,"43, 44, 45",Which component of a transformer block takes input from other tokens' residual streams?,Layer Normalization,Multi-Head Attention,Feed-Forward Neural Network,Gain and offset parameters,B) Multi-Head Attention
notes/LLM_cs124_week7_2025.pdf,22,"43, 44, 45",What is the result of the first step in layer normalization?,A new vector with zero mean and a standard deviation of one,A new vector with a mean of one and a standard deviation of zero,A new vector with a mean of zero and a standard deviation of one,A new vector with a mean of zero and a standard deviation of zero,C) A new vector with a mean of zero and a standard deviation of one
notes/LLM_cs124_week7_2025.pdf,22,"43, 44, 45",Which of the following is NOT a step in a single transformer block?,Layer Normalization of the input embedding vector,Multi-Head Attention,Feed-Forward Neural Network,Layer Normalization of the output from Multi-Head Attention,D) Layer Normalization of the output from Multi-Head Attention
notes/LLM_cs124_week7_2025.pdf,22,"43, 44, 45",What is the role of the learnable parameters g and b in layer normalization?,They are used for normalizing the input embedding vector,They are used for calculating the mean and standard deviation,They are used for adding the normalized vector to its original value,They are used for scaling and shifting the normalized vector,D) They are used for scaling and shifting the normalized vector
notes/LLM_cs124_week7_2025.pdf,23,"45, 46, 47","Given a transformer block with a single vector x of dimensionality d, which step calculates the mean and standard deviation of the vector?",Layer normalization after Multi-Head Attention,Layer normalization before Feedforward,Calculation of gain and offset parameters,Calculation of mean and standard deviation before normalization,D) Calculation of mean and standard deviation before normalization
notes/LLM_cs124_week7_2025.pdf,23,"45, 46, 47","Given a transformer block, which component takes input from other tokens (residual streams) and looks at all neighboring tokens in the context?",Layer normalization after Multi-Head Attention,Layer normalization before Feedforward,Multi-Head Attention,Feedforward,C) Multi-Head Attention
notes/LLM_cs124_week7_2025.pdf,23,"45, 46, 47","Given a transformer block, which step adds the output from attention into the current token's embedding stream?",Layer normalization after Multi-Head Attention,Layer normalization before Feedforward,Multi-Head Attention,Feedforward,A) Layer normalization after Multi-Head Attention
notes/LLM_cs124_week7_2025.pdf,23,"45, 46, 47","Given a transformer block, which step computes the gain and offset values?",Layer normalization after Multi-Head Attention,Layer normalization before Feedforward,Calculation of mean and standard deviation,Calculation of gain and offset parameters,D) Calculation of gain and offset parameters
notes/LLM_cs124_week7_2025.pdf,23,"45, 46, 47","Given a transformer block, which component computes the high-dimensional embeddings at each position that contains information about the current token and neighboring tokens?",Layer normalization after Multi-Head Attention,Layer normalization before Feedforward,Multi-Head Attention,Feedforward,C) Multi-Head Attention
notes/LLM_cs124_week7_2025.pdf,24,"47, 48, 49","Given a Transformer model with an input sequence of length 5, what is the shape of the embedding matrix X?",[5 × 2d],[5 × d],[10 × d],[5 × d × 2],C) [10 × d]
notes/LLM_cs124_week7_2025.pdf,24,"47, 48, 49",Which of the following shapes represents the embedding for a single input token and its positional information in a Transformer model?,[1× d],[1× 2d],[d],[2d],B) [1× 2d]
notes/LLM_cs124_week7_2025.pdf,24,"47, 48, 49","Consider a Transformer model with an input sequence of length 10. If the embedding size d is 128, what is the total number of embeddings in the matrix X?",1100,1280,10 × 128 = 1280,10 × 2 × 128 = 2560,C) 10 × 128 = 1280
notes/LLM_cs124_week7_2025.pdf,24,"47, 48, 49","Given a Transformer model with an input sequence of length 7, which shape best represents the shape of the matrix X?",[7 × 128],[7 × 2 × 128],[7 × 128 × 2],[7 × 128 × 1],A) [7 × 128]
notes/LLM_cs124_week7_2025.pdf,24,"47, 48, 49","Consider a Transformer model with an input sequence of length 6 and an embedding size of 128. If the positional embeddings are added to the token embeddings, what is the shape of the resulting matrix X?",[6 × 128],[6 × 2 × 128],[6 × 128 × 2],[6 × 256],C) [6 × 128 × 2]
notes/LLM_cs124_week7_2025.pdf,26,"51, 52, 53","Given the provided lecture content, which method is used for position embeddings in the simplest way?",Token Embeddings,Absolute Position Embeddings,Composite Embeddings,Transformer Block,B) Absolute Position Embeddings
notes/LLM_cs124_week7_2025.pdf,26,"51, 52, 53",Which shape does the position embedding matrix Epos have according to the lecture?,[N × 1],[1 × N],[N × N],[N × 3],B) [1 × N]
notes/LLM_cs124_week7_2025.pdf,26,"51, 52, 53",Which of the following is NOT a method mentioned for creating embeddings in the lecture?,Token Embeddings,Position Embeddings,Composite Embeddings,Random Embeddings,D) Random Embeddings
notes/LLM_cs124_week7_2025.pdf,26,"51, 52, 53",Which of the following is the correct shape for X in the equation X = CompositeEmbeddings(word + position)?,[N × N],[N × 1],[1 × N],[N × 3],A) [N × N]
notes/LLM_cs124_week7_2025.pdf,26,"51, 52, 53",Which of the following sentences demonstrates the concept of position embeddings in the context of the lecture?,Janet1will2back3Janetwillbackthebillthe4bill5,The quick brown fox jumps over the lazy dog,Isaac Newton discovered the law of gravity,Albert Einstein formulated the theory of relativity,A) Janet1will2back3Janetwillbackthebillthe4bill5
notes/LLM_cs124_week7_2025.pdf,27,"53, 54, 55","Given a [1 x d] vector output from a transformer block, which step is used to map it to a [1 x |V|] vector of logits?",Softmax function,Position Embeddings,Unembedding matrix,Word Embeddings,C) Unembedding matrix
notes/LLM_cs124_week7_2025.pdf,27,"53, 54, 55",Which function is used to map a [1 x |V|] vector of logits to a [1 x |V|] vector of probabilities?,Transformer Block,Unembedding matrix,Softmax function,Position Embeddings,C) Softmax function
notes/LLM_cs124_week7_2025.pdf,27,"53, 54, 55","Consider the following sequence: 'Janet will 2 back 3 Janet will back the bill the 4 bill 5'. If we apply a transformer block to this sequence and obtain a [1 x d] vector, which step is used to map it to a probability distribution over the vocabulary?",Position Embeddings,Word Embeddings,Unembedding matrix,Softmax function,D) Softmax function
notes/LLM_cs124_week7_2025.pdf,27,"53, 54, 55","Given a [1 x d] vector output from a transformer block, which step is used to map it to a [1 x |V|] vector of probabilities?",Position Embeddings,Word Embeddings,Unembedding matrix,Softmax function,D) Softmax function
notes/LLM_cs124_week7_2025.pdf,27,"53, 54, 55","Consider the following sequence: 'Janet will back the bill the 4 bill 5'. If we apply a transformer block to this sequence and obtain a [1 x d] vector, which step is used to map it to a probability distribution over the vocabulary?",Position Embeddings,Word Embeddings,Unembedding matrix,Softmax function,D) Softmax function
notes/LLM_cs124_week7_2025.pdf,28,"55, 56, 57","Given a [1 x 10] vector and a language modeling head, which layer transforms the vector into a [1 x |V|] vector of logits?",Unembedding layer,TransformerBlock,Softmax layer,Embedding layer,A) Unembedding layer
notes/LLM_cs124_week7_2025.pdf,28,"55, 56, 57",Which matrix maps a [1 x d] vector to a [1 x |V|] vector of logits in a language modeling head?,Unembedding matrix,Embedding matrix,TransformerBlock,Softmax layer,A) Unembedding matrix
notes/LLM_cs124_week7_2025.pdf,28,"55, 56, 57","Given a [1 x |V|] vector of logits, which layer is used to obtain the final probability distribution over the vocabulary?",Unembedding layer,TransformerBlock,Softmax layer,Embedding layer,C) Softmax layer
notes/LLM_cs124_week7_2025.pdf,28,"55, 56, 57",Consider a language modeling head with a hidden state hLN of size [d × 1]. What is the size of the output distribution over the vocabulary?,[1 × d],[1 × |V|],[d × |V|],[|V| × 1],B) [1 × |V|]
notes/LLM_cs124_week7_2025.pdf,28,"55, 56, 57",Which matrix has one column for each token in the vocabulary and a shape of [|V| × d]?,Unembedding matrix,Embedding matrix,TransformerBlock,Softmax layer,B) Embedding matrix
notes/LLM_cs124_week7_2025.pdf,29,"57, 58, 59","Given the transformer model architecture, which layer maps the output of the final transformer layer to a probability distribution over words in the vocabulary?",Unembedding layer,Transformer Block,Language Model Head,Linear Layer,C) Language Model Head
notes/LLM_cs124_week7_2025.pdf,29,"57, 58, 59",Which matrix is used to perform the reverse mapping from an embedding to a vector over the vocabulary in the language model head?,Embedding matrix,Unembedding matrix,Linear layer,Softmax layer,B) Unembedding matrix
notes/LLM_cs124_week7_2025.pdf,29,"57, 58, 59",What is the primary function of the unembedding layer in the transformer model?,Maps an embedding to a logit vector,Maps a logit vector to a probability distribution,Maps a probability distribution to a logit vector,Maps a one-hot vector to an embedding,D) Maps a one-hot vector to an embedding
notes/LLM_cs124_week7_2025.pdf,29,"57, 58, 59",Which layer in the transformer model takes the output of the final transformer layer and predicts the upcoming word?,Language Model Head,Transformer Block,Unembedding layer,Linear layer,A) Language Model Head
notes/LLM_cs124_week7_2025.pdf,29,"57, 58, 59",What is the shape of the logit vector produced by the language modeling head in the transformer model?,1 × d,d × 1,1 × |V|,|V| × 1,C) 1 × |V|
notes/LLM_cs124_week7_2025.pdf,30,"59, 60, 61","Given the transformer architecture described, which layer produces the logit vector for predicting the upcoming word in text generation?",Input token Language Model Head,Layer 1,Unembedding layer,Attention layer,A) Input token Language Model Head
notes/LLM_cs124_week7_2025.pdf,30,"59, 60, 61",Which matrix is used to map from the logit vector to the probability distribution over words in the vocabulary?,Embedding matrix,Unembedding matrix,Softmax function,Transformer block,B) Unembedding matrix
notes/LLM_cs124_week7_2025.pdf,30,"59, 60, 61",What is the primary function of the unembedding layer in the transformer architecture?,Maps from a one-hot vector to an embedding,Maps from an embedding to a vector over the vocabulary,Maps from the output of the final transformer layer to a probability distribution over words,Maps from the logit vector to the probability distribution over words,C) Maps from the output of the final transformer layer to a probability distribution over words
notes/LLM_cs124_week7_2025.pdf,30,"59, 60, 61",Which layer in the transformer architecture takes the output of the final transformer layer and produces a probability distribution over words?,Input token Language Model Head,Layer 1,Unembedding layer,Language Model Head,D) Language Model Head
notes/LLM_cs124_week7_2025.pdf,30,"59, 60, 61","Given a transformer model with a context window size of 4K tokens, what is the shape of the logit vector produced by the language modeling head?",1 × 4096,1 × 1024,1 × 4096 × 4096,1 × 4096 × 1,D) 1 × 4096 × 1
notes/LLM_cs124_week7_2025.pdf,31,"61, 62, 63",Which step comes first in the process of using a pre-trained transformer model for a new task?,Applying the transformer model to new tasks,Pretraining the transformer model on enormous amounts of text,Fine-tuning the transformer model on a smaller dataset,Extracting position embeddings from the input text,B) Pretraining the transformer model on enormous amounts of text
notes/LLM_cs124_week7_2025.pdf,31,"61, 62, 63",Which part of the transformer model is responsible for adding positional information to the input?,The Language Model Head,The Position Embeddings,The Encoder Layers,The Decoder Layers,B) The Position Embeddings
notes/LLM_cs124_week7_2025.pdf,31,"61, 62, 63",Which of the following tasks can be performed using a pre-trained transformer model without any additional training?,Text summarization,Sentiment analysis,Machine translation,Named entity recognition,C) Machine translation
notes/LLM_cs124_week7_2025.pdf,31,"61, 62, 63",Which of the following is a valid reason for pretraining a transformer model on enormous amounts of text?,To improve the model's ability to understand context,To make the model faster,To reduce the model's size,To make the model more interpretable,A) To improve the model's ability to understand context
notes/LLM_cs124_week7_2025.pdf,31,"61, 62, 63",Which of the following is a potential limitation of using a pre-trained transformer model for a new task without any additional training?,The model may not be able to understand the context of the new task,The model may be too large for the new task,The model may not be able to handle long sequences,The model may not be able to handle numerical data,A) The model may not be able to understand the context of the new task
notes/LLM_cs124_week7_2025.pdf,32,"63, 64, 65","Given a transformer model trained for language modeling, which step involves asking the model to predict the next word in a text corpus?",Training the model using gradient descent,Predicting the next word based on the current context,Pretraining the model on a large corpus of text,Calculating the probability distribution over the vocabulary,B) Predicting the next word based on the current context
notes/LLM_cs124_week7_2025.pdf,32,"63, 64, 65",Which part of a transformer model is responsible for language modeling tasks?,The transformer stack,The self-supervised training algorithm,The language modeling head,The loss function,C) The language modeling head
notes/LLM_cs124_week7_2025.pdf,32,"63, 64, 65",What is the goal of the self-supervised training algorithm in language model pretraining?,To minimize the error in predicting the previous word,To maximize the probability of the correct next word,To predict the next word based on the current context,To train the model on a large corpus of text,B) To maximize the probability of the correct next word
notes/LLM_cs124_week7_2025.pdf,32,"63, 64, 65",Which of the following is a correct description of the output of a language model?,A probability distribution over the entire text corpus,A single word as the next prediction,A probability distribution over the entire vocabulary,A probability distribution over the previous words in the text,C) A probability distribution over the entire vocabulary
notes/LLM_cs124_week7_2025.pdf,32,"63, 64, 65","Which of the following is a plausible next word prediction for the context 'So long and thanks for all the...', given a language model?",the,zebra,abaft,aardvark,A) the
notes/LLM_cs124_week7_2025.pdf,33,"65, 66, 67","Given the loss function for language modeling, which loss is used when the model assigns a high probability to the true word?",Cross-entropy loss when the model assigns a high probability to the true word,Cross-entropy loss when the model assigns a low probability to the true word,Regression loss when the model assigns a high probability to the true word,Regression loss when the model assigns a low probability to the true word,B) Cross-entropy loss when the model assigns a low probability to the true word
notes/LLM_cs124_week7_2025.pdf,33,"65, 66, 67",Which loss function is used in language modeling to measure the difference between the model's prediction and the true word?,Cross-entropy loss,Mean squared error loss,Absolute difference loss,Log loss,A) Cross-entropy loss
notes/LLM_cs124_week7_2025.pdf,33,"65, 66, 67","In teacher forcing, which tokens are used to compute the loss at each token position?",The model's predicted tokens,The correct tokens up to the current position,The model's predicted tokens and the correct tokens up to the current position,The correct tokens from the current position onwards,B) The correct tokens up to the current position
notes/LLM_cs124_week7_2025.pdf,33,"65, 66, 67",Which loss function is used in language modeling to encourage the model to assign a high probability to the true word?,Cross-entropy loss,Mean squared error loss,Absolute difference loss,Log loss,A) Cross-entropy loss
notes/LLM_cs124_week7_2025.pdf,33,"65, 66, 67","In teacher forcing, which tokens are ignored when computing the loss at each token position?",The model's predicted tokens,The correct tokens up to the current position,The model's predicted tokens and the correct tokens up to the current position,The correct tokens from the current position onwards,C) The model's predicted tokens and the correct tokens up to the current position
notes/LLM_cs124_week7_2025.pdf,34,"67, 68, 69",Which corpus is mainly used to train Language Model (LLM) models?,Common Crawl: snapshots of the entire web produced by the non-profit Common Crawl,Colossal Clean Crawled Corpus (C4),Filtered Wikipedia and news sites,Patent text documents,B) Colossal Clean Crawled Corpus (C4)
notes/LLM_cs124_week7_2025.pdf,34,"67, 68, 69",Which filtering is applied to the Colossal Clean Crawled Corpus (C4) to remove unwanted data?,Adult content and toxicity,Boilerplate and patent text documents,News sites and Wikipedia,Common Crawl snapshots,A) Adult content and toxicity
notes/LLM_cs124_week7_2025.pdf,34,"67, 68, 69",Which part of the transformer model computes the loss for the next token?,Language Modeling Head,Input Encoding,Stacked Transformer Blocks,Logits,A) Language Modeling Head
notes/LLM_cs124_week7_2025.pdf,34,"67, 68, 69",Which transformer block is responsible for ignoring the model's prediction for the next token?,Language Modeling Head,Input Encoding,Stacked Transformer Blocks,Teacher Forcing,D) Teacher Forcing
notes/LLM_cs124_week7_2025.pdf,34,"67, 68, 69",Which part of the transformer model takes the correct word for the next token and adds it to the context?,Language Modeling Head,Input Encoding,Stacked Transformer Blocks,Teacher Forcing,D) Teacher Forcing
notes/LLM_cs124_week7_2025.pdf,35,"69, 70, 71","Which corpus does LLMs primarily use for pretraining, containing billions of pages of web data?",Common Crawl,Colossal Clean Crawled Corpus,Wikipedia and news sites,Patent text documents,A) Common Crawl
notes/LLM_cs124_week7_2025.pdf,35,"69, 70, 71",Which filtering was applied to the Colossal Clean Crawled Corpus to remove unwanted content?,Adult content and toxicity,Boilerplate and patent text,News sites and Wikipedia,Canines and dogs,A) Adult content and toxicity
notes/LLM_cs124_week7_2025.pdf,35,"69, 70, 71",Which text source contributes the most to the knowledge contained in language models after pretraining?,Patent text documents,Wikipedia and news sites,Common Crawl,The author of 'A Room of One's Own' (Virginia Woolf),C) Common Crawl
notes/LLM_cs124_week7_2025.pdf,35,"69, 70, 71",Which of the following is NOT a common component of the text data used for pretraining language models?,News sites and Wikipedia,Patent text documents,Boilerplate and adult content,The square root of 4 is 2,D) The square root of 4 is 2
notes/LLM_cs124_week7_2025.pdf,36,"71, 72, 73",Which of the following is a potential issue with scraping text from the web for pretraining large language models?,Data consent is not an issue as website owners cannot indicate they don't want their site crawled,Copyright is not a concern as fair use doctrine in the US allows for this use of text,Privacy is not a concern as websites do not contain private IP addresses and phone numbers,Data is readily available and easy to access without any legal or ethical concerns,B) Copyright is not a concern as fair use doctrine in the US allows for this use of text
notes/LLM_cs124_week7_2025.pdf,36,"71, 72, 73",Which of the following is a potential concern for website owners regarding large language models pretraining on their text?,Data consent is a concern as they cannot prevent their site from being crawled,Privacy is a concern as their text may contain private IP addresses and phone numbers,Copyright is not a concern as fair use doctrine in the US allows for this use of text,Data is not a concern as they have given explicit permission for their text to be used,A) Data consent is a concern as they cannot prevent their site from being crawled
notes/LLM_cs124_week7_2025.pdf,36,"71, 72, 73",Which of the following is a potential issue with pretraining large language models on copyrighted text?,Data is readily available and easy to access,Website owners have given explicit permission for their text to be used,Fair use doctrine in the US allows for this use of text,Copyrighted text may contain inaccurate or outdated information,C) Fair use doctrine in the US allows for this use of text
notes/LLM_cs124_week7_2025.pdf,36,"71, 72, 73",Which of the following is a potential concern for privacy when pretraining large language models on text from the web?,"Websites may contain private IP addresses and phone numbers, but this is not a concern for privacy",Data consent is not an issue as website owners cannot prevent their site from being crawled,Privacy is not a concern as websites do not contain private information,"Websites may contain sensitive personal information, but this is not a concern for privacy","D) Websites may contain sensitive personal information, but this is not a concern for privacy"
notes/LLM_cs124_week7_2025.pdf,36,"71, 72, 73",Which of the following is a potential issue with pretraining large language models on text from the web that is not copyrighted but requires data consent?,Data is readily available and easy to access,Website owners have given explicit permission for their text to be used,Data consent is not an issue as website owners cannot prevent their site from being crawled,Data may contain inaccurate or outdated information,C) Data consent is not an issue as website owners cannot prevent their site from being crawled
notes/LLM_cs124_week7_2025.pdf,38,"75, 76, 77","Given a language model Q, what does the perplexity measure for an unseen test set of tokens w1:n?","The inverse probability that Q assigns to the test set, normalized by the test set length",The probability that Q assigns to the first token in the test set,The probability that Q assigns to the entire test set,The number of unique words in the test set,"A) The inverse probability that Q assigns to the test set, normalized by the test set length"
notes/LLM_cs124_week7_2025.pdf,38,"75, 76, 77",Which of the following methods is used to train a language model's classification head on new data while keeping the pretrained model frozen?,Continued pre-training,Parameter-efficient finetuning (PEFT),Supervised finetuning (SFT),Masked language model training,C) Supervised finetuning (SFT)
notes/LLM_cs124_week7_2025.pdf,38,"75, 76, 77","What is the inverse of the probability range for a language model, as perplexity is defined?","[0, 1]","[1, ∞]","[∞, 1]","[0, ∞]","B) [1, ∞]"
notes/LLM_cs124_week7_2025.pdf,38,"75, 76, 77","Which method is used to measure the quality of a language model by calculating the inverse probability of the test set, normalized by the test set length?",Perplexity,Cross-entropy loss,Accuracy,F1 score,A) Perplexity
notes/LLM_cs124_week7_2025.pdf,38,"75, 76, 77",Which of the following methods is used to train a language model to follow text instructions and produce a desired response?,Continued pre-training,Parameter-efficient finetuning (PEFT),Supervised finetuning (SFT),Instruction finetuning,D) Instruction finetuning
notes/LLM_cs124_week7_2025.pdf,39,"77, 78, 79",Which metric is used to evaluate the quality of language models by measuring the probability of the word sequence?,Perplexity,Accuracy,Fairness,Size,A) Perplexity
notes/LLM_cs124_week7_2025.pdf,39,"77, 78, 79",Which factor is NOT typically considered when evaluating large language models?,Perplexity,Size,Fairness,Energy efficiency,D) Energy efficiency
notes/LLM_cs124_week7_2025.pdf,39,"77, 78, 79",Which metric is used to measure the decrease in performance for language from or about certain groups in large language models?,Perplexity,Fairness,Size,Energy usage,B) Fairness
notes/LLM_cs124_week7_2025.pdf,39,"77, 78, 79",Which factor is a major concern when it comes to large language models due to their high energy usage?,Perplexity,Size,Fairness,Energy efficiency,D) Energy efficiency
notes/LLM_cs124_week7_2025.pdf,39,"77, 78, 79",Which metric is used to compare the performance of language models that use the same tokenizer?,Perplexity,Accuracy,Size,Fairness,A) Perplexity
notes/LLM_cs124_week7_2025.pdf,40,"79, 80, 81",Which phenomenon can lead large language models to generate incorrect or fabricated information?,Hallucination due to copyright infringement,Hallucination due to lack of training data,Hallucination due to model size,Hallucination due to power consumption,C) Hallucination due to model size
notes/LLM_cs124_week7_2025.pdf,40,"79, 80, 81",A large language model hallucinates when it:,Infringes on copyrighted material,Generates incorrect or fabricated information,Consumes excessive power,Learns from insufficient training data,B) Generates incorrect or fabricated information
notes/LLM_cs124_week7_2025.pdf,40,"79, 80, 81",Which issue is NOT a harm of large language models?,Power consumption,Copyright infringement,Hallucination,Lack of training data,B) Copyright infringement
notes/LLM_cs124_week7_2025.pdf,40,"79, 80, 81",A large language model hallucinates due to:,Insufficient training data,Excessive power consumption,Copyright infringement,Model size,D) Model size
notes/LLM_cs124_week7_2025.pdf,40,"79, 80, 81",Which harm of large language models is NOT directly related to the model's size?,Power consumption,Copyright infringement,Hallucination,Lack of training data,C) Hallucination
notes/LLM_cs124_week7_2025.pdf,41,"81, 82, 83",Which of the following is NOT a common topic addressed in online privacy policies?,Data collection and usage,Data security and protection,Cookies and tracking technologies,Terms of service and user agreements,D) Terms of service and user agreements
notes/LLM_cs124_week7_2025.pdf,41,"81, 82, 83",Suppose a user reports a comment containing hate speech on a social media platform. Which rule from the lecture content is most relevant to addressing this issue?,Privacy,Toxicity and Abuse,Copyright,Terms of service and user agreements,B) Toxicity and Abuse
notes/LLM_cs124_week7_2025.pdf,41,"81, 82, 83",Which of the following is a common method used by websites to remember user preferences and track online activity?,Data encryption,Cookies and tracking technologies,Two-factor authentication,Secure Sockets Layer (SSL),B) Cookies and tracking technologies
notes/LLM_cs124_week7_2025.pdf,41,"81, 82, 83",A user has agreed to a website's terms of service but later discovers that their data is being shared with third parties without their consent. Which rule from the lecture content is most relevant to this situation?,Privacy,Toxicity and Abuse,Copyright,Terms of service and user agreements,D) Terms of service and user agreements
notes/LLM_cs124_week7_2025.pdf,41,"81, 82, 83",Which of the following is a common method used to protect user data from unauthorized access?,Data encryption,Cookies and tracking technologies,Two-factor authentication,Secure Sockets Layer (SSL),A) Data encryption
notes/LLM_cs124_week7_2025.pdf,42,"83, 84, 85",Which type of online harm is most closely related to the spread of misinformation?,Toxicity and Abuse,Fraud,Phishing,Misinformation,D) Misinformation
notes/LLM_cs124_week7_2025.pdf,42,"83, 84, 85",Which harm can large language models inadvertently cause due to their ability to generate misleading or incorrect information?,Toxicity and Abuse,Fraud,Phishing,Misinformation,D) Misinformation
notes/LLM_cs124_week7_2025.pdf,42,"83, 84, 85","Which harm can large language models be used to facilitate, often through impersonation or deception?",Toxicity and Abuse,Fraud,Phishing,Misinformation,C) Phishing
notes/LLM_cs124_week7_2025.pdf,42,"83, 84, 85",Which harm is NOT directly related to large language models?,Toxicity and Abuse,Fraud,Phishing,Misinformation,B) Fraud
notes/LLM_cs124_week7_2025.pdf,42,"83, 84, 85","Which harm can large language models contribute to, even unintentionally, due to their vast knowledge base and ability to generate text?",Toxicity and Abuse,Fraud,Phishing,Misinformation,D) Misinformation
notes/LLM_cs124_week7_2025.pdf,43,"85, 86, 87","Given a neural network with a loss of 5.2 and a learning rate of 0.01, what is the updated weight if the current weight is 3.5 and the partial derivative is -2.1?",2.9,3.3,3.7,4.1,A) 2.9
notes/LLM_cs124_week7_2025.pdf,43,"85, 86, 87",Which step in the neural network training process calculates the loss between the estimated output and the target output?,Forward computation,Backward computation,Weight update,Loss calculation,D) Loss calculation
notes/LLM_cs124_week7_2025.pdf,43,"85, 86, 87","Assuming a neural network has a loss of 3.8 and a learning rate of 0.05, which weight update would decrease the loss?",wnew = w + η,wnew = w - η,wnew = w * η,wnew = w / η,B) wnew = w - η
notes/LLM_cs124_week7_2025.pdf,43,"85, 86, 87",Which of the following is a step in the neural network training process that assesses how much blame each weight deserves for the current loss?,Forward computation,Backward computation,Weight update,Loss calculation and partial derivative calculation,D) Loss calculation and partial derivative calculation
notes/LLM_cs124_week7_2025.pdf,43,"85, 86, 87","Given a neural network with a loss of 4.5 and a learning rate of 0.02, which weight update would result in the smallest loss for a weight with a partial derivative of 1.2?",wnew = w + η,wnew = w - η,wnew = w * η,wnew = w / η,B) wnew = w - η
notes/LLM_cs124_week7_2025.pdf,44,"87, 88, 89","Given a simple 1-layer neural network with initial weights w1=2, w2=-1, b=1, and using squared loss function, what is the network's output for input (x1, x2) = (4, -3)?",6,12,10,8,B) 12
notes/LLM_cs124_week7_2025.pdf,44,"87, 88, 89","Given a simple 1-layer neural network with initial weights w1=2, w2=-1, b=1, and using squared loss function, what is the loss for the input (x1, x2) = (4, -3) and the true output ytrue = 10?",0,1,9,11,C) 9
notes/LLM_cs124_week7_2025.pdf,44,"87, 88, 89",Which of the following is NOT a part of the neural network training process mentioned in the lecture?,Run backward computation and update weights,Run forward computation to find the estimate,Compute loss between the estimated output and the true output,Assess how much blame each weight deserves for the current loss,D) Assess how much blame each weight deserves for the current loss
notes/LLM_cs124_week7_2025.pdf,44,"87, 88, 89","Given a simple 1-layer neural network with initial weights w1=2, w2=-1, b=1, and using squared loss function, what is the new weight w1 after one training iteration with learning rate η=.01 and input (x1, x2) = (4, -3)?",1.99,1.98,1.97,2.01,A) 1.99
notes/LLM_cs124_week7_2025.pdf,45,"89, 90, 91","Given the forward pass computation: w1 = 2, w2 = -1, b = 1, x1 = 4, x2 = -3, y = 12, ytrue = 10. Which intermediate variable is used to compute the loss?",w1,w2,x1,y,D) y
notes/LLM_cs124_week7_2025.pdf,45,"89, 90, 91","Assuming the same forward pass computation as above, which key node is used to update the gradients in the backward pass?",w1,w2,b,y,A) w1
notes/LLM_cs124_week7_2025.pdf,45,"89, 90, 91","Given the forward pass computation: w1 = 2, w2 = -1, b = 1, x1 = 4, x2 = -3, y = 12, ytrue = 10. What is the value of the loss?",1,2,4,10,C) 4
notes/LLM_cs124_week7_2025.pdf,45,"89, 90, 91","In the context of the provided lecture content, which of the following is a key node in the computation graph?",x1,w1,b,ytrue,B) w1
notes/LLM_cs124_week7_2025.pdf,45,"89, 90, 91","Given the forward pass computation: w1 = 2, w2 = -1, b = 1, x1 = 4, x2 = -3, y = 12, ytrue = 10. Which of the following is the correct value for y?",10,12,14,16,B) 12
notes/LLM_cs124_week7_2025.pdf,46,"91, 92, 93","Given a neural network with parameters w1, w2, b, and intermediate variable h1, which nodes need to be included in the computation graph during the backward pass?",Only w1 and w2,"Only w1, w2, and b",Only h1 and h2,Only y and L,"B) Only w1, w2, and b"
notes/LLM_cs124_week7_2025.pdf,46,"91, 92, 93",Which intermediate variables h1 and h2 are created during the forward pass of the backward pass in a neural network?,w1x1 and w2x2,w1 and w2,x1 and x2,h1 and h2,D) h1 and h2
notes/LLM_cs124_week7_2025.pdf,46,"91, 92, 93",Which nodes in the computation graph are updated during the backward pass of a neural network?,Only the loss node,Only the intermediate nodes,Only the weight and bias nodes,Both the intermediate and weight and bias nodes,D) Both the intermediate and weight and bias nodes
notes/LLM_cs124_week7_2025.pdf,46,"91, 92, 93","Given a neural network with the loss function L=(ytrue- y)2, which intermediate variable is used to compute the loss gradients for w2?",h1,h2,y,x1,B) h2
notes/LLM_cs124_week7_2025.pdf,46,"91, 92, 93",Which of the following nodes is NOT created during the backward pass in a neural network?,w1,w2,b,h1,A) w1
notes/LLM_cs124_week7_2025.pdf,47,"93, 94, 95","Given the backpropagation equation for computing the gradient of the loss with respect to weight w1x1, which term is multiplied by -1?",h1,w1x1,ytrue,2y,B) w1x1
notes/LLM_cs124_week7_2025.pdf,47,"93, 94, 95","In the backpropagation equation for computing the gradient of the loss with respect to weight w1x1, which term represents the input feature value?",h1,w1x1,y,x1,D) x1
notes/LLM_cs124_week7_2025.pdf,47,"93, 94, 95","Given the backpropagation equation for computing the gradient of the loss with respect to weight w2x2, which term represents the output label?",h1,w1x1,ytrue,y,C) ytrue
notes/LLM_cs124_week7_2025.pdf,47,"93, 94, 95","In the backpropagation equation for computing the gradient of the loss with respect to bias b, which term represents the output label?",h1,w1x1,ytrue,y,C) ytrue
notes/LLM_cs124_week7_2025.pdf,47,"93, 94, 95","Given the backpropagation equation for computing the gradient of the loss with respect to weight h1, which term represents the input feature value?",h1,w1x1,y,x1,A) h1
notes/LLM_cs124_week7_2025.pdf,48,"95, 96, 97","Given the backpropagation equation, which term represents the weight between the second hidden layer and the output layer?",w1x1,h1 + h2 + b,w2x2,2(ytrue-y),C) w2x2
notes/LLM_cs124_week7_2025.pdf,48,"95, 96, 97","In the backpropagation equation, what value is assigned to 'h1'?",h1 = w1x1 + h2 + b,h1 = w1x1 + h2 + bh1,h1 = w2x2 + h2 + b,h1 = w1x1 + h2,B) h1 = w1x1 + h2 + bh1
notes/LLM_cs124_week7_2025.pdf,48,"95, 96, 97",Which term in the backpropagation equation represents the error between the true output and the predicted output?,ytrue,y,h1 + h2 + b,2(ytrue-y),D) 2(ytrue-y)
notes/LLM_cs124_week7_2025.pdf,48,"95, 96, 97","In the backpropagation equation, which term represents the weight between the input layer and the first hidden layer?",w1,w2,bh1,w1x1,A) w1
notes/LLM_cs124_week7_2025.pdf,48,"95, 96, 97","Given the backpropagation equation, which term represents the weight between the first hidden layer and the second hidden layer?",w1x1,h1 + h2 + b,w2x2,w2,C) w2x2
notes/LLM_cs124_week7_2025.pdf,49,"97, 98, 99","Given the backpropagation equation, what is the value of dw1 in terms of w1, x1, y, ytrue, and b?",w1 + 2(ytrue - y) * h1 + b,w1 - 1.84 * x1 + 0.96 * x2 - 0.88 * y,w1 - 1.84 * x2 - 0.88 * y + 2(ytrue - y) * h1,w1 + 1.84 * x1 - 0.96 * x2 + 0.88 * y,B) w1 - 1.84 * x1 + 0.96 * x2 - 0.88 * y
notes/LLM_cs124_week7_2025.pdf,49,"97, 98, 99",Which of the following is the correct equation for computing the gradient of the loss with respect to w2?,16x2 = -3y + 12ytrue,-12 = 4 * x1 + 4 * x2 - 3y,4 = -12 * w2 + 16 * x2,12 = -12 * w2 + 4 * x2,A) 16x2 = -3y + 12ytrue
notes/LLM_cs124_week7_2025.pdf,49,"97, 98, 99","Given the backpropagation equation, what is the value of db in terms of w1, w2, x1, x2, y, and ytrue?",1 - 0.01 * 4,1 - 0.01 * 16,1 + 0.01 * 4,1 + 0.01 * 16,B) 1 - 0.01 * 16
notes/LLM_cs124_week7_2025.pdf,49,"97, 98, 99",Which of the following is the correct equation for computing the gradient of the loss with respect to b?,2(ytrue - y) = h1 + h2 + b,2(y - ytrue) = h1 + h2 - b,h1 + h2 = 2(y - ytrue) + b,h1 + h2 = 2(ytrue - y) - b,B) 2(y - ytrue) = h1 + h2 - b
notes/LLM_cs124_week7_2025.pdf,49,"97, 98, 99","Given the backpropagation equation, what is the value of dw1 in terms of w1, x1, y, ytrue, and b, if w2 is known to be -1?",w1 + 2(ytrue - y) * h1 + b,w1 - 1.84 * x1 + 0.96 * x2 - 0.88 * y,w1 - 1.84 * x2 - 0.88 * y + 2(ytrue - y) * h1,w1 + 1.84 * x1 - 0.96 * x2 + 0.88 * y,A) w1 + 2(ytrue - y) * h1 + b
notes/LLM_cs124_week7_2025.pdf,50,"99, 100, 101","Given the backpropagation weights update rules provided, which weight will have the smallest update value?",w1,w2,b,-12,D) -12
notes/LLM_cs124_week7_2025.pdf,50,"99, 100, 101","If the learning rate η is increased, which weight will have a larger update value?",w1,w2,b,w1 - η * 𝜕𝐿𝜕𝑤1,D) w1 - η * 𝜕𝐿𝜕𝑤1
notes/LLM_cs124_week7_2025.pdf,50,"99, 100, 101","Given the backpropagation weights update rules, which weight update is equivalent to subtracting 0.96 from the current weight value?",w1 = w1 - η * 𝜕𝐿𝜕𝑤1,w2 = w2 - η * 𝜕𝐿𝜕𝑤2,b = b - η * 𝜕𝐿𝜕𝑏,w1 = w1 - 0.96,A) w1 = w1 - η * 𝜕𝐿𝜕𝑤1
notes/LLM_cs124_week7_2025.pdf,50,"99, 100, 101","If the input features x1 and x2 are multiplied by a constant factor of 2, which weight update rule will change to accommodate this change?",w1 = w1 - η * 𝜕𝐿𝜕𝑤1,w2 = w2 - η * 𝜕𝐿𝜕𝑤2,b = b - η * 𝜕𝐿𝜕𝑏,w1 = w1 - η * 𝜕𝐿𝜕𝑤1 * 2,D) w1 = w1 - η * 𝜕𝐿𝜕𝑤1 * 2
notes/LLM_cs124_week7_2025.pdf,50,"99, 100, 101","Given the backpropagation weights update rules, which weight update is equivalent to adding 1.84 to the current weight value?",w1 = w1 - η * 𝜕𝐿𝜕𝑤1,w2 = w2 - η * 𝜕𝐿𝜕𝑤2,b = b - η * 𝜕𝐿𝜕𝑏,w1 = w1 + 1.84,D) w1 = w1 + 1.84
notes/LLM_cs124_week7_2025.pdf,51,"101, 102, 103","Given a multi-head attention layer with 3 heads, what is the shape of the output from each head?",[1 x d],[1 x hdv],[hdv x d],[1 x dv],D) [1 x dv]
notes/LLM_cs124_week7_2025.pdf,51,"101, 102, 103","Which matrices are used to project the inputs into separate key, value, and query embeddings for each head in a multi-head attention layer?","WK, WQ, WV","WQ, WK, WV","WK, WV, WQ","WQ, WV, WK","B) WQ, WK, WV"
notes/LLM_cs124_week7_2025.pdf,51,"101, 102, 103","What is the shape of the key, query, and value embeddings for each head in a multi-head attention layer?",[d x dk],[d x dv],[dk x d],[dv x dk],A) [d x dk]
notes/LLM_cs124_week7_2025.pdf,51,"101, 102, 103","Given a multi-head attention layer with 8 heads, what is the shape of the output from the multi-head attention layer?",[1 x 8dv],[8 x 1dv],[1 x d],[8 x d],A) [1 x 8dv]
notes/LLM_cs124_week7_2025.pdf,51,"101, 102, 103",Which linear projection is used to reshape the output of the multi-head attention layer to the correct output shape?,WO,WO2,WQ,WV,B) WO2
notes/LLM_cs124_week7_2025.pdf,52,"103, 104, 105","Given a multi-head attention layer with d as the model dimension, hdv as the output size per head, and A as the number of attention heads, what is the shape of the output of the multi-head attention layer?",[1 x d],[1 x hdv],[hdv x d],[N x d],C) [hdv x d]
notes/LLM_cs124_week7_2025.pdf,52,"103, 104, 105",Which matrix multiplication is used to compute all query-key comparisons in a single step for a single attention head?,QK|,QWK,XWQK,VQK,A) QK|
notes/LLM_cs124_week7_2025.pdf,52,"103, 104, 105",What is the purpose of masking in the self-attention computation?,To eliminate knowledge of words that follow in the sequence,To reduce the computational complexity of attention,To increase the dimensionality of the input embeddings,"To project the inputs into separate key, value, and query embeddings for each head",A) To eliminate knowledge of words that follow in the sequence
notes/LLM_cs124_week7_2025.pdf,52,"103, 104, 105","What is the shape of the key, query, and value matrices in a single attention head?",[d x dk],[d x dv],[dk x d],[dv x dk],A) [d x dk]
notes/LLM_cs124_week7_2025.pdf,52,"103, 104, 105","Which of the following matrices is used to produce matrices Q, K, and V for all tokens in the input sequence?","XWQ, XWK, XWV","QK|, KQ|, VQ|","XWQ, XWK, XWV, QK|","XWQ, XWK, XWV, VQ|","C) XWQ, XWK, XWV, QK|"
notes/LLM_cs124_week7_2025.pdf,53,"105, 106, 107","Given a single attention head, which matrices are multiplied to produce matrices Q, K, and V?","X, WQ, WK, WV","X, WQ, W, V","X, W, WQ, WK","X, W, WK, WV","A) X, WQ, WK, WV"
notes/LLM_cs124_week7_2025.pdf,53,"105, 106, 107",Which portion of the masked QK|matrix is set to zero in language modeling?,Lower-triangular portion,Upper-triangular portion,Diagonal portion,Randomly selected elements,B) Upper-triangular portion
notes/LLM_cs124_week7_2025.pdf,53,"105, 106, 107",What is the shape of the output of a single attention head?,N × d,N × dk,N × dv,N × dk × dv,C) N × dv
notes/LLM_cs124_week7_2025.pdf,53,"105, 106, 107","In multi-head attention, how many matrices are there for each head?",1,2,3,4,C) 3
notes/LLM_cs124_week7_2025.pdf,53,"105, 106, 107",What is the final shape of the output from the multi-head attention layer?,N × d,N × dk,N × dv,N × hdv,D) N × hdv
notes/LLM_cs124_week7_2025.pdf,54,"107, 108, 109","Given the self-attention computation described in the text, what is the purpose of adding a mask matrix to the upper-triangular portion of the QK|matrix?",To increase the computational complexity of the attention mechanism,To eliminate knowledge of words that follow in the sequence during language modeling,To reduce the dimensionality of the input and output,To add random noise to the attention scores,B) To eliminate knowledge of words that follow in the sequence during language modeling
notes/LLM_cs124_week7_2025.pdf,54,"107, 108, 109","In multi-head attention, what is the shape of the output of each attention head for a single token?",A matrix of shape N×d,A matrix of shape N×dv,A vector of shape d,A vector of shape dv,B) A matrix of shape N×dv
notes/LLM_cs124_week7_2025.pdf,54,"107, 108, 109",What is the purpose of the final linear projection (WO) in multi-head attention?,To concatenate the outputs of all attention heads,To reshape the output to the original output dimension for each token,To apply a non-linear activation function to the output,To multiply the output of each attention head by its corresponding weight matrix,B) To reshape the output to the original output dimension for each token
notes/LLM_cs124_week7_2025.pdf,54,"107, 108, 109",Which portion of the QK|matrix is masked out in the self-attention computation?,The lower-triangular portion,The diagonal portion,The upper-triangular portion,The constant portion,C) The upper-triangular portion
notes/LLM_cs124_week7_2025.pdf,54,"107, 108, 109",What is the computational complexity of attention in terms of the length of the input?,Linear,Quadratic,Exponential,Logarithmic,B) Quadratic
notes/LLM_cs124_week7_2025.pdf,55,"109, 110, 111","Given a masked QK| matrix, which elements are set to zero?",Lower-triangular elements,Upper-triangular elements,Diagonal elements,Randomly selected elements,B) Upper-triangular elements
notes/LLM_cs124_week7_2025.pdf,55,"109, 110, 111",Why is the upper-triangular portion of the QK| matrix set to zero in masking?,To reduce the computational complexity,To increase the computational complexity,To eliminate knowledge of future words in language modeling,To improve the accuracy of the model,C) To eliminate knowledge of future words in language modeling
notes/LLM_cs124_week7_2025.pdf,55,"109, 110, 111","In multi-head attention, how many matrices are concatenated to produce a single output?",One,Two,Three,Four,C) Three
notes/LLM_cs124_week7_2025.pdf,55,"109, 110, 111",What is the shape of the output of a single attention head?,N x dk x NN x dv,N x dk x NN x dk,N x dv x NN x dk,N x dk x NN x d,B) N x dk x NN x dk
notes/LLM_cs124_week7_2025.pdf,55,"109, 110, 111",Which of the following is NOT a component of the multi-head attention computation?,Multiplication of input by weight layers,Concatenation of outputs from each head,Final linear projection,Softmax activation,D) Softmax activation
notes/LLM_cs124_week7_2025.pdf,56,"111, 112, 113","Given a sequence of tokens, where does the transformer obtain the input embeddings from?",Output of the MultiHeadAttention function,Output of the FFN function,Input of the LayerNorm function,"Input of the transformer block, separately computed as input token and positional embeddings","D) Input of the transformer block, separately computed as input token and positional embeddings"
notes/LLM_cs124_week7_2025.pdf,56,"111, 112, 113",Which function computes the self-attention output of shape [N⇥d]?,MultiHeadAttention,SelfAttention,LayerNorm,FFN,B) SelfAttention
notes/LLM_cs124_week7_2025.pdf,56,"111, 112, 113","What shape does the input and output of transformer blocks have, allowing them to be stacked?",[N⇥(d⇥d)],[N⇥d],[N⇥(d⇥N)],[N⇥(d⇥1)],B) [N⇥d]
notes/LLM_cs124_week7_2025.pdf,56,"111, 112, 113",Which function applies the same FFN in parallel to each of the N embedding vectors in the window?,MultiHeadAttention,SelfAttention,LayerNorm,FFN,D) FFN
notes/LLM_cs124_week7_2025.pdf,56,"111, 112, 113","Given an input token string, how are the token embeddings selected from the embedding matrix?",By indexing the corresponding rows using the vocabulary indices,By multiplying the input token string with the embedding matrix,By converting the input token string to a one-hot vector,By applying the LayerNorm function to the input token string,A) By indexing the corresponding rows using the vocabulary indices
notes/LLM_cs124_week7_2025.pdf,57,"113, 114","Given a sequence of tokens with length N, what shape does the matrix X of token embeddings have?",[N⇥|V|],[N⇥d],[d⇥N],[|V|⇥d],B) [N⇥d]
notes/LLM_cs124_week7_2025.pdf,57,"113, 114",Which of the following is NOT a component of the transformer block computation?,LayerNorm(X+MultiHeadAttention(X)),LayerNorm(O+FFN(O)),MultiHeadAttention(X),FFN(T3),D) FFN(T3)
notes/LLM_cs124_week7_2025.pdf,57,"113, 114","Given an input token string, how are token embeddings selected from the embedding matrix E?",By multiplying the embedding matrix with the one-hot vector of the token index,By indexing the embedding matrix with the token index,By summing the embedding matrix rows with the token index,By subtracting the embedding matrix rows with the token index,A) By multiplying the embedding matrix with the one-hot vector of the token index
notes/LLM_cs124_week7_2025.pdf,57,"113, 114",What is the shape of the input X and output H for a transformer block with context length N?,[N⇥d],[N⇥|V|],[d⇥N],[|V|⇥d],A) [N⇥d]
notes/LLM_cs124_week7_2025.pdf,57,"113, 114",Which of the following is NOT a transformer block computation step?,LayerNorm(X+MultiHeadAttention(X)),LayerNorm(O+FFN(O)),MultiHeadAttention(X),LayerNorm(X),D) LayerNorm(X)
